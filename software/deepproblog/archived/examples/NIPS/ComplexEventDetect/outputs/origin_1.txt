source /home/nothing/miniconda3/bin/activate
conda activate DPL
(base) nothing@nothing:~/Code/ece209as_project$ source /home/nothing/miniconda3/bin/activate
(base) nothing@nothing:~/Code/ece209as_project$ conda activate DPL
(DPL) nothing@nothing:~/Code/ece209as_project$ cd '/home/nothing/Code/ece209as_project/software/deepproblog/archived/examples/NIPS/ComplexEventDetect'
(DPL) nothing@nothing:~/Code/ece209as_project/software/deepproblog/archived/examples/NIPS/ComplexEventDetect$ python run.py
Training for 1 epochs (10000 iterations).
/home/nothing/miniconda3/envs/DPL/lib/python3.9/site-packages/torch/nn/modules/module.py:1033: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
^CInterrupted!
^C
(DPL) nothing@nothing:~/Code/ece209as_project/software/deepproblog/archived/examples/NIPS/ComplexEventDetect$ python run.py
Training for 1 epochs (10000 iterations).
/home/nothing/miniconda3/envs/DPL/lib/python3.9/site-packages/torch/nn/modules/module.py:1033: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Accuracy 0.84
Epoch 1
step loss:  0.5506873711296401
step loss:  0.4661991618716999
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
Iteration:  100         Average Loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
Iteration:  200         Average Loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
Iteration:  300         Average Loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
Iteration:  400         Average Loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
step loss:  nan
Iteration:  500         Average Loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  nan
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  -9.999999889225291e-09
step loss:  nan
step loss:  nan
^CInterrupted!
step loss:  nan
Epoch time:  47.93423271179199
^C
(DPL) nothing@nothing:~/Code/ece209as_project/software/deepproblog/archived/examples/NIPS/ComplexEventDetect$ ^C
(DPL) nothing@nothing:~/Code/ece209as_project/software/deepproblog/archived/examples/NIPS/ComplexEventDetect$ 