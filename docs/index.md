# Abstract

In our project, we decided to inject human knowledge into convolutional LSTM models, so that we do not need to process a series of activities all at once. To that end, we can use convolutional LSTM just to process a window size of signal series to distinguish a single activity, and then apply human knowledge to it by decision tree or othersymbolic methods. As a result, that will make the convolutional LSTM model small and simple enough to deploy on edge devices. In our design, our project should achieve 90%+ accuracy for complex event detection and long range of window size to prove that the model is robust to long-term reasoning.

# Team

* Liying Han \#1 
* Yuxuan Fan \#2
* Weitao Sun \#3

# Required Submissions

* [Proposal](https://github.com/7hgTnec/ece209as_project/blob/main/docs/proposal.md)
* [Midterm Checkpoint Presentation Slides](https://docs.google.com/presentation/d/18IcK4QDl5yYhPo6qwylZUW1ROw1Au8vDhAAk5Ylnbbk/edit#slide=id.g116c54ca3fb_2_121)
* [Final Presentation Slides](https://docs.google.com/presentation/d/18IcK4QDl5yYhPo6qwylZUW1ROw1Au8vDhAAk5Ylnbbk/edit?pli=1#slide=id.g132d07ad5bb_0_0)
* [Final Report](https://github.com/7hgTnec/ece209as_project/blob/main/docs/report.md)
